\documentclass{new_tlp}

\input pheader18.tex
%\usepackage{pldoc}

\usepackage{hyperref}

\begin{document}

%\title[A Unified View of (Lazy) Generators in Prolog]{All Rivers Flow to The Sea: A Unified %View of (Lazy) Generators in Prolog}

\title{Lazy Stream Programming in Prolog}

%\begin{comment}
\author[Paul Tarau, Jan Wielemaker and Tom Schrijvers]
          {    Paul Tarau\\
%          Dept. of Computer Science and Engineering 
%          \\ University of North Texas\\
%          1155 Union Circle, Denton, Texas 76203, USA\\
          { paul.tarau@unt.edu}
          \and
          Jan Wielemaker\\
          { J.Wielemaker@vu.nl}
          \and
          Tom Schrijvers\\
          { tom.schrijvers@cs.kuleuven.be}
}          
%\end{comment}

\maketitle



\begin{abstract}
In recent years, stream processing has become a prominent approach for incrementally handling large amounts of data, with special support and libraries in many programming languages. Unfortunately, support in Prolog has so far been lacking and most existing approaches are ad-hoc. To remedy this situation, we present {\em lazy stream generators} as a unified Prolog interface for stateful computations on both finite and infinite sequences of data that are produced incrementally through I/O and/or algorithmically.

We expose stream generators to the application programmer in two ways: 1) through an abstract sequence manipulation API, convenient for defining custom generators, and 2) as idiomatic lazy lists, compatible with many existing list predicates.  We define an algebra of stream generator operations that extends Prolog via an embedded language interpreter, provides a compact notation for composing generators and supports moving between the two isomorphic representations.

As a special instance, we introduce answer stream generators that encapsulate the work of coroutining first-class logic engines and support interoperation between forward recursive {\em AND-streams} and backtracking-generated {\em OR-streams}. 

{\bf Keywords:}
lazy stream generators,
lazy lists,
first-class logic engines,
stream combinators,
AND-stream / OR-stream interoperation,
Prolog extensions

\end{abstract}

\begin{comment}
\begin{abstract}
Lazy stream generators provide a unified interface to stateful computations, I/O operations as well as algorithms producing finite or infinite sequences. 

As a special instance, we introduce answer stream generators that 
encapsulate the work of coroutining first-class logic engines and support interoperation between forward recursive {\em AND-streams} and backtracking-generated {\em OR-streams}. 

Stream generators are exposed to the application programmer either through an abstract sequence manipulation API or as lazy lists. We define an algebra of stream generator operations that extends Prolog via an embedded language interpreter providing a compact notation for composition mechanisms and supports moving between isomorphic sequence representations.
\end{abstract}
\end{comment}
\hrule


%===============================================================================
\section{Introduction}

Initial design as well as evolution of successful programming languages often walks a fine line between semantic purity and pragmatic expressiveness. With its declarative roots and creative pragmatic additions Prolog is a long-time survivor in the complex ecosystem of programming languages. We believe that its longevity is due not only to its elegant semantics but also to its creative adaptations to emerging programming language features that respond to evolving software development requirements.

\emph{Stream processing}---now prevalent in widely used programming languages
languages like Java, Python, C\#, go or JavaScript---offers a uniform and
(mostly) declarative view on processing finite and infinite\footnote{We use
``infinite'' here as a short hand for data or computation streams of
unpredictable, large or very large size.} sequences. Besides the expressiveness
boost it provides, its advent has been driven by the need for processing big
data. This big data problem manifests itself in static incarnations like very
large training sets for machine learning, or as dynamic event streams coming
from Web search queries and clicks, or from sensor networks supporting today's
fast spreading IoT infrastructure. 


The main goal of this paper is to extend Prolog with state-of-the-art lazy
stream processing capabilities like those available in other languages.
While some languages facilitate such an extension with features like
generalized iterators (Python) or a lazy evaluation semantics (Haskell), 
Prolog presents two major obstacles that make this task particularly challenging.

The first obstacle is presented by Prolog's fixed depth-first search resolution
and strict evaluation semantics. While Prolog's depth-first search mechanism
can be complemented with alternative search strategies, as shown by \citeN{tor}
by overriding its disjunction operator, the evaluation mechanism remains
ultimately eager. When programming with lists or DCGs, one chains recursive
steps in the body of clauses connected by conjunctions. 

The second obstacle, a consequence of Prolog's incremental evolution as a
programming language, is the presence of procedural state-management and I/O
constructs that are interleaved with its native declarative programming
constructs. These range form random generator streams to file and socket I/O
and dynamic database operations.  While monadic constructs in functional
languages \cite{moggi:monads,wadler93:cont}  can provide  a unified view of
declarative and procedural state-management operations, logic programming
languages still lack a unified approach providing a uniform interface to this
mix of declarative and procedural language constructs.

 
We manage to overcome these obstacles and provide lazy stream
processing for Prolog in a way that uniformly encapsulates
different streaming mechanisms---state transformers, lazy lists and first-class logic engines 
%\cite{tarau:parimp99,tarau:cl2000,iclp08:inter,ciclops08:pINTER,bp2011},
\cite{tarau:cl2000,padl09inter,bp2011}, 
recently added to SWI-Prolog\footnote{
\url{http://www.swi-prolog.org/pldoc/man?section=engines}
---} into a set of operations organized compositionally in the form of {\em 
stream generators}.
Our generators work in a way similar to Python's {\em yield} mechanism \cite{pyref,beazley09} and 
they share features with coroutining constructs now present in a several  programming languages including C\#, go, Javascript and Lua. At the same time, 
they lift Prolog's expressiveness with lazy evaluation mechanisms similar to non-strict
functional programming languages like Haskell \cite{hudak07} or functional-logic languages like Curry \cite{antoy05}.

We organize our generators as an algebra, wrapped as a library module with a declarative interface, to avoid exposing  operations requiring an implementation with a clear procedural flavor to the Prolog application programmer.

By defining a functor that transports operations between isomorphic
generators and lazy lists, we offer a choice between 
abstract sequence operations and the concrete list view familiar to Prolog users.

% At the same time, it makes sense to expose stream generators as abstract
% sequence-manipulation operators, independent of the specific list
% representation of possibly infinite, lazily produced streams coming from I/O
% operations, coroutining logic engines or some complex computations that one
% might want to declaratively aggregate into an algebra of stream combinators.


The main contributions of this paper are:
\BI
\I We present a simple and clean approach for setting up lazy streams.
\I We provide a technique to expose lazy streams in the form of (lazy) Prolog lists
   that can be inspected and decomposed, with unification, just like conventional lists.
   The technique uses attributed variables and destructive updates under the hood to
   extend the list as needed.
\I We have implemented our approach in two libraries:
   \BI 
   \I Our \texttt{lazy\_streams} library
features a dozen generator predicates (stream sources), an API to query
them, a set of generator  operations, a generator expression interpreter
offering a declarative view of these operations and an interface to
the other library. 
cases.
   \I Our \texttt{lazy\_lists} library provides a dozen generator predicates for 
      directly setting up lazy lists.
   \EI
   The \texttt{lazy\_streams} library is available as an SWI-Prolog
library package\footnote{
\url{https://github.com/ptarau/AnswerStreamGenerators/raw/master/lazy_streams-0.5.0.zip}}
  and the \texttt{lazy\_lists} library is bundled as a standard library\footnote{\url{http://www.swi-prolog.org/pldoc/doc/_SWI_/library/lazy_lists.pl}} with SWI-Prolog.
\EI

The rest of the paper is organized as follows.
Section \ref{ov} demonstrates our approach with some examples.
Section \ref{impl} describes implementation of lazy stream generator constructors and 
their the interface.
Section \ref{alg} introduces several operations on generators and overviews the
embedded language interpreter organizing then as an algebra of generator combinators.
Section \ref{other} describes lazy functional language style generator operations
and an example of I/O stream generator.
Section \ref{ll} overviews implementation of lazy lists using attributed variables
and introduces the iso-functor connecting them to  lazy stream generators.
Section \ref{disc} compares lazy list and stream generators 
and discusses some alternative implementation options. 
Section \ref{rel} overviews related work and
section \ref{conc} concludes the paper.

%===============================================================================
\section{Overview}\label{ov}

This section briefly introduces our lazy streams approach with a few examples.

The generators {\tt pos/1} and {\tt neg/1} produce the infinite streams of positive
and negative integers. With {\tt map/4} we combine these two streams element-wise;
here they annihilate each other with {\tt plus/3}. With {\tt show/2} we display
the first 10 elements of the resulting constant stream of zeroes.
\begin{codex}
?- pos(P),neg(N),map(plus,P,N,Zero),show(10,Zero).
[0, 0, 0, 0, 0, 0, 0, 0, 0, 0].
\end{codex}
With \texttt{list/2} we turn the regular list \texttt{[a,b,c]} into a stream.
Then {\tt convolution/3} computes its Cartesian product with the positive
integers, following a convolution approach, and {\tt show/2} displays the first 16 elements. 
\begin{codex}
?- pos(P),list([a,b,c],L),convolution(P,L,C),show(16,C).
[1-a, 1-b, 2-a, 1-c, 2-b, 3-a, 2-c, 3-b, 4-a, 3-c, 4-b, 5-a, 4-c, 5-b, 6-a, 5-c].
\end{codex}
We also provide an embedded language interpreter to concisely 
express algebraic operations on stream. Here we use it to create
the Cartesian product of the stream \texttt{[a,b]} with the stream
\texttt{[1,2,3]}, the latter abbreviated by the shorthand \texttt{(1:4)}.
The \texttt{in\_/2} predicate enumerates the elements of the resulting stream
through backtracking, like \texttt{member/2} does for regular lists.
\begin{codex}
?- X in_ [a,b]*(1:4).
X = a-1 ; X = b-1 ; X = b-2 ; X = a-2 ; X = b-3 ; X = a-3 .
\end{codex}
     

%===============================================================================
\section{Implementing Lazy Stream Generators}\label{impl}
  
Generators are created by a family of constructors, encapsulating sequences produced algorithmically or as a result of state transformers interfacing Prolog with the ``outside world'', a design philosophy similar to that of monads in functional languages.

%-------------------------------------------------------------------------------
\subsection{The Stream Generator Interface}

The ``contract'' of our interface is that a generator, specified by a 
closure that moves it one step further is called by the {\tt ask/2} predicate, defined as follows:
\begin{code}
ask(E,_):-is_done(E),!,fail.
ask(E,R):-call(E,X),!,R=X.
ask(E,_):-stop(E),fail.
\end{code}
Note  the checking for completed generators by {\tt is\_done/1} and the explicit termination by {\tt stop/1}, on failure. Once failed, a generator is never invoked and its resources
are garbage collectable.

The single {\em advancement steps} provided by {\tt ask/2} can be morphed into an answer stream generated on backtracking with the infix predicate {\tt in/2}, as if it were a list explored by {\tt member/2}.
\begin{code}
:-op(800,xfx,(in)).

X in Gen:-ask(Gen,A),select_from(Gen,A,X).

select_from(_,X,X).
select_from(Gen,_,X):-X in Gen.
\end{code}

The simplest generator is the infinite constant stream constructor, {\tt const/2}:
\begin{code}
const(C,=(C)).
\end{code}
When activated by {\tt ask/2}, it produces the next element with
``\verb~call(=(Constant),X)~'', as {\tt call/2} triggers unification of {\tt X} with {\tt Constant}.

Another generator constructor, relying this time on an externally maintained state, is {\tt rand/1}.
\begin{code}
rand(random()).
\end{code}
This generator, when called by {\tt ask/2}, will produce a stream of random floating point numbers between 0 and 1, with help from the built-in predicate {\tt random/1}.

A generic constructor for a stream that evolves by incremental state changes is
\begin{code}
gen_next(F,State,X):-arg(1,State,X),call(F,X,Y),nb_setarg(1,State,Y).
\end{code}
Thus, {\tt State} acts as a container for destructively updated values using the built-in
{\tt nb\_setarg/3}\footnote{\url{http://www.swi-prolog.org/pldoc/doc_for?object=nb_setarg/3}}.

%\subsection{Generators as Simple State Transformers}

In terms of {\tt gen\_next}, the stream of natural numbers is defined as:
\begin{code}
nat(nat_next(state(0))).

nat_next(S,X):-gen_next(succ,S,X).
\end{code}

Generators for which state-update and value-yield are distinct,
can be obtained as specializations of {\tt gen\_nextval/3}.
\begin{code}
gen_nextval(Advancer,State,Yield):-
  arg(1,State,X1),
  call(Advancer,X1,X2, Yield),
  nb_setarg(1,State,X2).
\end{code}

For instance, by using {\tt gen\_nextval}, one can turn a list into a generator of its elements  in the form of the {\tt list/2} generator constructor.
\begin{code}
list(Xs, gen_nextval(list_step,state(Xs))).

list_step([X|Xs],Xs,X).
\end{code}

\BX
Using some simple generators.
\begin{codex}
?- nat(N),X in N.
N = nat_next(state(1)), X = 0 ; N = nat_next(state(2)), X = 1 ; ...

?- list([a,b],L),X in L.
L = gen_nextval(list_step, state([b, c])), X = a ;
L = gen_nextval(list_step, state([c])), X = b .
\end{codex}
\EX

We have built similar stream generators in the library package 
{\tt lazy\_streams}, for a range of numbers, turning a finite list into
a an infinite cycle of its elements, as well as stream 
transformers excising a finite slice of a larger, possibly infinite stream,
as well as for taking or dropping an initial segment of a stream.

\subsection{Answer Stream Generators}

When more complex computations are involved, that  cannot be expressed as simple step-by-step state transformations, a more powerful mechanism is needed. We will use {\em generator constructors based on first class logic engines} in this case, but we will expose their workings in terms of the same interface.

\subsubsection{SWI Prolog's First-Class Logic Engine Implementation}

A first-class logic engine \cite{tarau:cl2000,bp2011} can be seen as a Prolog virtual machine that has its own stacks and machine state. 
In their SWI-Prolog implementation, unlike normal Prolog threads \cite{swi,swi_threads}, they are not associated with an operating system thread. Instead, one asks an engine for a next answer with the predicate {\tt engine\_next/2}. Asking an engine for the next answer attaches the engine to the calling operating system thread and causes it to run until the engine calls {\tt engine\_yield/1} or its associated goal completes with an answer, failure or an exception. After the engine yields or completes, it is detached from the operating system thread and the answer term is made available to the calling thread. Communicating with an engine is similar to communicating with a Prolog system though the terminal: the client decides how many answers it wants returned and what to do with them.  

Engines are created with the built-in {\tt engine\_create/3} that uses a goal and and answer template as input and returns an engine handle as output. SWI-Prolog's engines are created with minimal dynamic stack space and are garbage collected when unreachable.

Note that, implementing the engine API does not need  a Prolog system that supports multi-threading. It only assumes that the virtual machine is fully reentrant, it can be queried and that it can stop, yield data and resume execution as a {\em coroutine}.

\begin{comment}
As Prolog virtual machines, engines have  an internal state. Thus interacting with them requires a concise and expressive, but ultimately procedural API. This is not very different from what working with attributed variables, instrumental to adding constraint solvers, requires.
\end{comment}

\subsubsection{Answer Stream Generator Constructors}

We design Answer Stream Generator constructors as a wrapper around the SWI-Prolog engine implementation.
The constructor {\tt eng/3} creates a generator as a wrapper for
the {\tt engine\_next(Engine,Answer)} built-in.
\begin{code}
eng(X,Goal,engine_next(Engine)):-engine_create(X,Goal,Engine). 
\end{code}
An alternative constructor, {\tt ceng/3}, is also available if one wants to preserve
the goal and answer template, usable, for instance, to clone
the engine's answer stream, an
operation that makes sense only when the Prolog code it is based on 
is free of side effects.

\subsection{The AND-stream / OR-stream Duality}

We call {\em AND-stream / OR-stream duality} the
ability of first-class logic engines
 to generate the same answer stream via backtracking (OR-streams) or
as part of a forward moving recursive loop (AND-streams).
As the examples that follow will show,
being oblivious to the choice of generation method they encapsulate,
is a key contributor to the ``expressiveness lift'' answer stream
generators bring to Prolog.

An example of {\em AND-stream} is  implemented
by the generator {\tt and\_nat\_stream}. 
It defines the infinite stream of natural numbers 
by yielding an answer at each step of a recursive loop.
\begin{code}
and_nat_stream(Gen):-eng(_,nat_goal(0),Gen).

nat_goal(N):-SN is N+1,engine_yield(N),nat_goal(SN).
\end{code}

Alternatively, one could define 
an equivalent generator as an OR-stream,  with answers 
produced via  backtracking.
\begin{code}
or_nat_stream(Gen):-eng(N, nat_from(0,N), Gen).

nat_from(From,To):- From=To ; succ(From,Next),nat_from(Next,To).
\end{code}

When using engines, 
both AND-streams and OR-streams can be infinite, as in the
case of the generators {\tt or\_nat\_stream} and {\tt and\_nat\_stream}.
While one can see backtracking over an infinite set of answers as
a ``naturally born'' OR-stream, the ability of the generators to
yield answers from inside an infinite recursive loop is critical
for generating infinite AND-streams.

Note also that generating an answer stream by either of the above methods
is immaterial to the user of the generator which can be seen as a ``black box''.


%===============================================================================
\section{The Generator Algebra}\label{alg}
We start by describing some of the stream generator combinators
that will be organized into a generator algebra 
via an embedded language interpreter.
 
\subsection{Operations on Finite or  Infinite Stream Generators}

\subsubsection{Merging generators: our {\em sum} operation}

The predicate {\tt sum(+Gen1,+Gen2, -NewGen)} advances by asking each generator, in turn, for an answer. When one generator terminates, it keeps progressing in the other.
\begin{code}
sum(E1,E2,sum_next(state(E1,E2))).

sum_next(State,X):-State=state(E1,E2),ask(E1,X),!,
  nb_setarg(1,State,E2),
  nb_setarg(2,State,E1).
sum_next(state(_,E2),X):-ask(E2,X).
\end{code}

\subsubsection{Pairing all elements from two streams: our {\em product} operation}

The easiest way to implement direct product uses a first-class logic engine.
Designing the recursive loop for possibly infinite stream generators
will need to store finite initial 
segments of the generators as they grow into two lists, initially
empty.
\begin{code}
prod(E1,E2,E):-eng(_,prod_goal(E1,E2),E).

prod_goal(E1,E2):-ask(E1,A),prod_loop(1,A,E1-[],E2-[]).
\end{code}

The algorithm, expressed by the predicate {\tt prod\_loop}
switches between generators while none of them is done.
After that, it keeps progressing the active generator 
for new pairs, including those selecting an element 
from the stored lists of the terminated generator.
\begin{code}
prod_loop(Ord1,A,E1-Xs,E2-Ys):-
  flip(Ord1,Ord2,A,Y,Pair),
  forall(member(Y,Ys),generate_answer(Pair)),
  ask_generator(E2,B),
  !,
  prod_loop(Ord2,B,E2-Ys,E1-[A|Xs]).
prod_loop(Ord1,_A,E1-_Xs,_E2-Ys):-
  flip(Ord1,_Ord2,X,Y,Pair),
  X in E1,member(Y,Ys),
  generate_answer(Pair),
  fail.
\end{code}

The predicate {\tt flip/5} ensures correct order in a given pair
as  generators take turn being the active one in the recursive loop. 
\begin{code} 
flip(1,2,X,Y,X-Y).
flip(2,1,X,Y,Y-X).
\end{code}

The package {\tt lazy\_streams} also provides the {\tt prod/3} stream product 
operation that avoids the engine creation and collection overhead,
coming from the use of the constructor {\tt eng/3} by using the Cantor
unpairing function  to split natural numbers generated by {\tt nat/1}
that are used to index dynamic arrays growing with each new element consumed
from the two input streams. By using the  $N \rightarrow N^k$ generalized Cantor
 untupling function implemented for instance in \cite{serpro}, one can obtain efficient
 generator  product operations for $k$ generators.


\BX
Working with infinite sums and products. The  predicate {\tt show/1} (defined in the package) exposes a short initial segment of a generator.
\begin{codex}
?- nat(N),nat(M),sum(N,M,E),show(E).
[0,0,1,1,2,2,3,3,4,4,5,5]
...
?- nat(N),nat(M),prod_(N,M,R),show(R).
[0-0,1-0,1-1,0-1,2-1,2-0,2-2,1-2,0-2,3-2,3-1,3-0]
...
\end{codex}
\EX




\paragraph{Some algebraic properties of sums and products.}
As {\tt sum/2} simply interleaves two streams, it is clearly associative and
if  the order of the elements is unimportant, it is also commutative. 
Up to an isomorphism that ignores the specific pair representations, the product is also associative. Under the same assumptions, the products are distributive over sums.
The empty stream, defined such that {\tt ask/2}  fails, acts as neutral element for the sum. Any constant stream, up to an isomorphism ignoring the specific pair representation
being or not decorated with the constant, acts as a neutral element for the product.

\subsection{An embedded language interpreter for the algebra}

With our sum and product operations ready, we can proceed with the design of the embedded language, facilitating more complex forms of generator compositions.

\subsubsection{Working with Sets}

If generators work over sets rather than multisets or arbitrary sequences,
duplicates need to be removed. This can be done either by sorting (which has the advantage
of providing a canonical representation, but assumes finite streams) or by using  a built-in like {\tt distinct/2} which will also work with infinite generators (within the limits of actual memory available).

The predicate {\tt setify} wraps a generator to ensure it produces a set of answers, with duplicates removed.
\begin{code}
setify(E,SE):-eng(X,distinct(X,X in E),SE).
\end{code}
In fact, one could just apply the same modification to the goal of a generator and its answer template, but our assumption here is that the generator's engine might be a composition of several engine operations, possibly already in progress.

We can implement our generator algebra as an embedded language via a simple interpreter
(although partial evaluation can make this more efficient). 

The predicate  {\tt eval\_stream(+GeneratorExpression, -Generator)}
evaluates a generator expression to a ready to use generator that combines 
the effects of its components.
\begin{code}
eval_stream(E+F,S):- !,eval_stream(E,EE),eval_stream(F,EF),sum(EE,EF,S).
eval_stream(E*F,P):- !,eval_stream(E,EE),eval_stream(F,EF),prod(EE,EF,P).
eval_stream(E:F,R):- !,range(E,F,R).
eval_stream([X|Xs],L):-!,list([X|Xs],L).
eval_stream({E},SetGen):-!,eval_stream(E,F),setify(F,SetGen).
eval_stream(X^G,E):-!,eng(X,G,E).
eval_stream(A,C):-atomic(A),!,const(A,C).
eval_stream(E,E).
\end{code}
Similarly to the {\tt in/2} predicate, we can make the action of the
interpreter transparent, via the {\tt in\_/2} predicate, also defined as an operator.
\begin{code}
:-op(800,xfx,(in_)).

X in_ GenExpr:-eval_stream(GenExpr,NewGen),X in NewGen.     
\end{code}

\BX
Applying the embedded language interpreter to a generator expression.
\begin{codex}
?- X in_ ({[a,b,a]}+(1:3)*c).
X = a ; X = 1-c ; X = b ; X = 1-c ; X = 2-c; X = 1-c ; X = 2-c ....
\end{codex}
\EX



\section{Other Stream Generator Operations}\label{other}
We describe next other operations on stream generators
implemented in the package {\tt lazy\_streams}.

\subsection{Lazy Functional Programming Constructs}

\subsubsection{Map}

The predicate {\tt map/3} creates a new generator that
applies a predicate with two arguments to the answer stream  of a generator.
It uses the predicate {\tt map\_next/3}, that advances the generator
and yields the result of applying the closure {\tt F} to what
the generator yields.
\begin{code}
map(F,Gen,map_next(F,Gen)).

map_next(F,Gen,Y):-ask(Gen,X),call(F,X,Y).
\end{code}

Our package contains similarly defined {\tt map/N} generators that
apply a predicate with {\tt N-1 arguments} to
{\tt N-1} stream generators.

\subsubsection{Reduce}

The predicate {\tt reduce(+Closure, +Generator, +InitialVal, -ResultGenerator)}
creates a generator that reduces a given generator's yields with the given closure, 
starting with an initial value. Its only yield is the resulting single final value.
Similarly to {\tt foldl} and {\tt foldr} in a language like Haskell, it can be used to
define, generically, arithmetic sums or products over a stream,
as done in our {\tt lazy\_streams} package.

\begin{code}
reduce(F,InitVal,Gen, reduce_next(state(InitVal),F,Gen)).
\end{code}
It uses the predicate {\tt reduce\_next/4} 
that  applies closure {\tt F} to the state {\tt S}, 
while generator {\tt E} provides ``next'' elements.
\begin{code}
reduce_next(S,F,E,R):- \+ is_done(E),
  do((
    Y in E, arg(1,S,X),
    call(F,X,Y,Z),
    nb_setarg(1,S,Z)
  )),
  arg(1,S,R).

do(G):-call(G),fail;true.
\end{code}
Note that by working in $O(1)$ space, with destructive updates,
we can handle streams with an arbitrary number of elements.
\subsection{Wrappers on I/O and stateful procedural Prolog constructs}

One can easily wrap file or socket readers as generators, with the
advantage that details like opening a file, reading and
closing a stream stay hidden,  as shown by the generator
{\tt term\_reader/2}, an advantage, for instance, 
when teaching Prolog to a beginner.

\begin{code}
term_reader(File,next_term(Stream)):-open(File,read,Stream).

next_term(Stream,Term):-read(Stream,X),
  ( X\==end_of_file->Term=X
  ; close(Stream),fail
  ).
\end{code}


\section{Generators and Lazy Lists}\label{ll}

While generators provide abstract sequence operations, it is also useful
to emulate as closely as possible the  list operations familiar to the 
Prolog programmer with {\em lazy lists}. 
As an example, they can elegantly express parsing algorithms acting on files 
via Prolog's DCGs.

\subsection{Implementing lazy lists using attributed variables}

Lazy lists form a suitable representation of infinite streams of Prolog
terms. Lazy data structures can be implemented in Prolog using
\emph{attributed} variables as a mechanism to extend unification
\cite{holz92}. 
The lazy function implementation of
Ciao \cite{lazyCiao,casas2005functional}
exploits the widely supported
\texttt{freeze/1} primitive that is usually implemented using attributed
variables. A lazy \emph{list} is represented as a normal Prolog list where the
\emph{tail} is formed by an attributed variable. Normal list traversal
predicates unify this tail with either the empty list (\texttt{[]}) or a
list cell (\texttt{[Head|Tail]}), which triggers the goal associated
with the attributed variable.

A significant disadvantage of this technique is that. on backtracking, the
lazily computed extension to the list is lost. In addition to causing
overhead for recomputing the value, this makes the implementation
unsuitable for fetching data from an external source that cannot
backtrack. A typical example of such a source is a network socket. It is
possible to keep a buffer to support re-fetching content from the socket
but the amount of data we need to buffer depends on the unknown
non-determinism in the Prolog code that processes the list and we cannot
recover if the selected buffer size proves to be too short.

The above limitation can be avoided using \emph{not-backtrackable
assignment} as implemented by various Prolog systems. Where SICStus
solves this problem using a dedicated \emph{mutable term}, SWI-Prolog
provides
\texttt{nb\_setarg/3}
for assigning an argument in a compound term where the assignment is not
undone on backtracking. SWI-Prolog's lazy lists are realized using an
attributed variable that resides in the tail argument of the last list
cell and keeps a reference to this last cell. When triggered, the next
value(s) is/are computed and the tail of the current last cell is set to
the new lazy list using \texttt{nb\_setarg/3}. As this binding is not
undone on backtracking only the first unification triggers the goal
associated with the attributed variable. Initially, a lazy list is
represented using a term \texttt{[dummy|AttVar]}, where the lazy list
itself is the  \texttt{AttVar}.

The above technique is used to implement the library \texttt{pure\_input}, supporting a list view of file or socket operations, 
as well as the generic
\texttt{lazy\_lists}\footnote{\url{http://www.swi-prolog.org/pldoc/doc/_SWI_/library/lazy_lists.pl?show=src\#lazy_list/3}}
library. The general goal to create a lazy list is
\texttt{lazy\_list(:Next, +State0, -List)}. This executes
\texttt{call(Next, State0, State1, Head)} to produce the next element.

Lazy lists allow Prolog to handle infinite data streams,  provided that garbage
collection can reclaim the inaccessible head of the list. To make the
head inaccessible, the code cannot keep a reference to the head
and although processing the list may be non-deterministic,
this non-determinism must be resolved after examining a finite number of
elements.  The attributed variable trigger and garbage collection ensure
that the window on the stream that is kept in memory is finite and
guaranteed to be large enough to cope with the finite non-determinism.

% ref: https://cliplab.org/papers/lazy-functions-ciclops05.pdf

For instance, 
using the constructor  {\tt lazy\_list/3}, we implement the infinite list of
natural numbers as follows.
\begin{code}
lazy_nats(L):-lazy_list(lazy_nats_next,0,L).

lazy_nats_next(X,SX,X):-succ(X,SX).
\end{code}


%\subsection{The Lazy List View of Prolog Streams}
%\subsection{The  equivalence between Answer stream generators and Lazy Lists}
\subsection{The interoperation between stream generators and lazy lists}

The overloading of syntax between the usual lists and lazy lists, 
can be confusing to the
programmer, especially when infinite streams are involved.

\BX
\begin{codex}
?- lazy_nats(Ns),maplist(succ,Ns,Ps).
... loops forever ...
\end{codex}
\EX
The {\tt maplist/3} example
 shows that sharing the concrete syntax between lazy lists and  ordinary lists
does not automatically entail that the semantics is shared between them.

We will alleviate this problem by designing interoperation mechanisms between lazy lists and lazy streams resulting in operations like {\tt maplist/3} to be implemented with support for infinite lazy lists.

First, let's observe that  {\em advancing to the next element}, 
whether it happens via a destructive update,
a first class engine's yield operation or by setting an attribute on the tail of
a lazy list are {\em operationally equivalent}.

By lifting this equivalence with help from Prolog's higher order operations
supported by {\tt call/N}, we can easily transport not just  data representations 
but also   operations acting on them.
The more formal analogy to this is an {\em iso-functor}, that in category theory
transports morphisms between objects of a category to another and back. 

With help from SWI-Prolog's {\tt lazy\_lists} library, 
generators can be turned into finite or infinite lazy lists and vice-versa.
The predicate {\tt gen2lazy(+Generator,-LazyList)} turns a possibly infinite
stream generator into a lazy list.
\begin{code} 
gen2lazy(Gen,Ls):-lazy_list(gen2lazy_forward,Gen,Ls).

gen2lazy_forward(E,E,X):-ask(E,X).
\end{code}
As {\tt Gen}  manages the advancement of its own state, 
we just pass on the action of the {\tt ask/2}
generator stream advancer.
By observing that the stream constructor {\tt list/2} already works
on lazy lists, we define the inverse operation {\tt lazy2gen} simply as:
\begin{code}
lazy2gen(Xs, Gen):-list(Xs, Gen).
\end{code}

Next we define the ``iso-functors'' that 
lift this equivalence between data objects to 
one between their operations. We do that as generically as possible,
but one can specialize them to the fixed stream and lazy list domain
for slightly more efficient code.

The predicate 
{\tt iso\_fun(+Operation, +SourceType, +TargetType, +Arg1, -Result)}
transports a predicate of the form {\tt F(+Arg1, -Arg2)} to a domain where
an operation can be performed and brings back the result.

\begin{code}
iso_fun(F,From,To,A,B):-call(From,A,X),call(F,X,Y),call(To,Y,B).
\end{code}
Similar code is defined for predicates of different arities,
{\tt iso\_fun(+Operation, +SourceType, +TargetType, +Arg1, +Arg2, -Result)} 
or, with a different mode
{\tt iso\_fun\_( +Operation, +SourceType, +TargetType, +Arg1, -Res1, -Res2)}.

\begin{codeh}
%
% Transports a predicate of arity 2 F(+A,+B,-C) to a domain where
% an operation can be performed and brings back the result. 
% transports F(+A,+B,-C) 
iso_fun(F,From,To,A,B,C):-
  call(From,A,X),
  call(From,B,Y),
  call(F,X,Y,Z),
  call(To,Z,C).

%! iso_fun_(+Operation,+SourceType,+TargetType,+Arg1, -Res1, -Res2)
%
% Transports a predicate of arity 2 F(+A,-B,-C) to a domain where
% an operation can be performed and brings back the results. 
% transports F(+A,+B,-C) 
iso_fun_(F,From,To,A,B,C):- 
  call(From,A,X),
  call(F,X, Y,Z), % X in, Y,Z out 
  call(To,Y,B),
  call(To,Z,C).
\end{codeh}


This allows us to define {\tt maplist} predicates working also
on infinite lazy lists as:

\begin{code}
lazy_maplist(F,LazyXs,LazyYs):-iso_fun(map(F),lazy2gen,gen2lazy,LazyXs,LazyYs).
\end{code}
where {\tt map/3} is the stream generator constructor that applies a binary
predicate to a stream generator. In our package, similar definitions for {\tt map/N}
are given for predicates of higher arities, as well as corresponding definitions for
{\tt lazy\_maplist/N} predicates.

\BX
\begin{codex}
?- lazy_nats(Ns),lazy_maplist(succ,Ns,Ps),member(X,Ps).
Ns = [0|_20314], Ps = [1|_20332], X = 1,
...
Ns = [0|_20668], Ps = [1, 2|_20692], X = 2,
...
Ns = [0|_21022], Ps = [1, 2, 3|_21052], X = 3,
...
\end{codex}
\EX

On the other hand, an alternative {\tt sum\_/3} operation  can be implemented 
quite easily with lazy lists. Our package {\tt lazy\_streams} 
uses this technique to borrow it with help from the {\tt iso\_fun/6} predicate.
\begin{code}
sum_(E1,E2, E):-iso_fun(lazy_sum,gen2lazy,lazy2gen,E1,E2, E).

lazy_sum(Xs,Ys,Zs):-lazy_list(lazy_sum_next,Xs-Ys,Zs).
  
lazy_sum_next([X|Xs]-Ys,Ys-Xs,X).
lazy_sum_next(Xs-[Y|Ys],Ys-Xs,Y).
\end{code}

\section{Discussion}\label{disc}

The abstract sequence interface of the {\tt lazy\_streams} package and
the concrete list-based view provided by the lazy lists library offer
similar services, but as they interoperate with help of {\tt iso\_fun} predicates,
one can choose the  implementation most suitable for a given algorithm.

For instance, one  can access the N-th element of a  generator in $O(1)$ space.
Lazy lists might or might not need $O(N)$ for the same, depending on possible garbage collection of their unused prefix.
With most stream generators no garbage collection is needed when working destructively in constant space, while their results can be exposed declaratively via the stream algebra.

On the other hand, lazy lists are reusable, while new generators 
must be created if the sequence needs to be revisited again.

Some algorithms can be most easily expressed using first-class logic engines, but
avoiding engines when possible reduces memory footprint and can avoid term copying.
Thus, one might ask if predicates like {\tt lazy\_findall} could be implemented
without using first class logic engines, e.g., it terms of  
attributed-variables, 
TOR \cite{tor}, delimited AND-continuations \cite{delim}.

This unlikely, as  these techniques are all subject to backtracking and as such can not
store state that survives it. We know that one can circumvent this challenge
by emulating first-class engines at source level as in \cite{padl09inter}, but that is 
extremely slow, way beyond being practical. A more promising
way to achieve  that would be to support
OR-continuations, in an implementation that fully reflects Prolog's backtracking
mechanism.

\section{Related work}\label{rel}

\begin{comment}
Maybe?
\BI 
\I some history - see
\cite{tarau:parimp99,tarau:cl2000,iclp08:inter,ciclops08:pINTER}
\cite{coord11tarau}
\cite{bp2011}
\I work on delimited continuations \cite{delim}, hookable disjunction \cite{tor}
\I work on pipelines \cite{pipelines}
\EI
\end{comment}

A relational view of stream processing and querying has been 
present in the database community 
\cite{Law11,Babcock02},
and 
within logic programming 
\cite{Beck15}, %,Beck18}, 
the later with focus on
reasoning about streams.
Our lazy stream generators share with Python  \cite{pyref} the encapsulation of
a stream into a mechanism providing its elements on-demand. 
Adoption of a very similar mechanism by other widely
used languages validates the claims of 
enhanced expressiveness  that generators can bring.
The basic idea of using coroutining in the form of first-class logic engines
has been present in the BinProlog system  \cite{bp2011} as early as 1995 and
the attributed variables  mechanism \cite{holz92} that we used to implement 
lazy lists, has been present even earlier, originally introduced to support constraint programming. However, putting it all together
in the form of a mature API that relies as much as possible
 on implementations that bypass both first-class engines and lazy lists is a 
 novel contribution of this paper,
 as well as the uniform view  encapsulating into an open-source library 
 our mix of declarative and procedural implementation techniques. 
 
\section{Conclusions}\label{conc}

We have described a unified approach to program with finite or infinite stream generators
that enhances Prolog with operations now prevalent in widely used programming languages
like Python, C\#, go, JavaScript, Ruby and Lua, while also supporting lazy evaluation mechanisms comparable to those in non-strict functional languages like Haskell.
As a special instance of our stream generators,
we have defined first-class logic engine based generator constructors 
that can expose sequence  generation
originating from AND-streams or OR-streams of answers.

Our generator algebra supported by an embedded language interpreter provides
a declarative expression of stream algorithms in the form of compact and elegant code.

We have shown that interoperation mechanisms 
between lazy stream generators and their 
equivalent lazy lists representation
supports transporting operations from one side to the other,
allowing one to choose the simplest and/or more efficient
implementation of stream operations.

Among the applications that can benefit from the use of our stream generators, we mention the following.
Stream processing  can be parallelized when streams originate from  arrays or
file systems supporting  direct access.
% event streams can be seen as generators 
Generator operations can express algorithms for working with multiple streams 
e.g., scanning tweets for a common topic,  finding correlations in multiple stock quote streams or integrating multiple IOT signal streams.
Combinatorial generation algorithms, e.g., when used for automated test generation, can be encapsulated as lazy streams.
Prolog interfaces to  ASP or SAT solvers, returning answers sets as streams can benefit from stream combinator operations.

Code supporting the paper has been implemented as an open source library package at:\\
{\small \url{https://github.com/ptarau/AnswerStreamGenerators/raw/master/lazy_streams-0.5.0.zip } }
The reader is encouraged to explore its functionality using SWI-Prolog's {\tt pack\_install/1} utility that downloads and installs it as SWI-Prolog library.

\bibliographystyle{acmtrans}
\bibliography{theory,tarau,proglang,biblio,new}

\end{document}
