\documentclass{new_tlp}
\input pheader18.tex

\begin{document}

%\title[A Unified View of (Lazy) Generators in Prolog]{All Rivers Flow to The Sea: A Unified %View of (Lazy) Generators in Prolog}

\title{Lazy Stream Programming in Prolog}

%\begin{comment}
\author[Paul Tarau, Jan Wielemaker, Tom Schrijvers and Koen Pauwels]
          {    Paul Tarau\\
%          Dept. of Computer Science and Engineering 
%          \\ University of North Texas\\
%          1155 Union Circle, Denton, Texas 76203, USA\\
          { paul.tarau@unt.edu}
          \and
          Jan Wielemaker\\
          { J.Wielemaker@vu.nl}
          \and
          Tom Schrijvers\\
          { tom.schrijvers@cs.kuleuven.be}
          \and
          Koen Pauwels\\
          { koen.pauwels@cs.kuleuven.be}
}          
%\end{comment}

\maketitle



\begin{abstract}
In recent years, stream processing has become a prominent approach for incrementally handling large amounts of data, with special support and libraries in many programming languages. Unfortunately, support in Prolog has so far been lacking and most existing approaches are ad-hoc. To remedy this situation, we present {\em lazy stream generators} as a unified Prolog interface for stateful computations on both finite and infinite sequences of data that are produced incrementally through I/O and/or algorithmically.

We expose stream generators to the application programmer in two ways: 1) through an abstract sequence manipulation API, convenient for defining custom generators, and 2) as idiomatic lazy lists, compatible with many existing list predicates.  We define an algebra of stream generator operations that extends Prolog via an embedded language interpreter, provides a compact notation for composing generators and supports moving between the two isomorphic representations.

As a special instance, we introduce answer stream generators that encapsulate the work of coroutining first-class logic engines and support interoperation between forward recursive {\em AND-streams} and backtracking-generated {\em OR-streams}. 

{\bf Keywords:}
lazy stream generators,
lazy lists,
first-class logic engines,
stream combinators,
AND-stream/OR-stream interoperation,
Prolog extensions

\end{abstract}

\begin{comment}
\begin{abstract}
Lazy stream generators provide a unified interface to stateful computations, I/O operations as well as algorithms producing finite or infinite sequences. 

As a special instance, we introduce answer stream generators that 
encapsulate the work of coroutining first-class logic engines and support interoperation between forward recursive {\em AND-streams} and backtracking-generated {\em OR-streams}. 

Stream generators are exposed to the application programmer either through an abstract sequence manipulation API or as lazy lists. We define an algebra of stream generator operations that extends Prolog via an embedded language interpreter providing a compact notation for composition mechanisms and supports moving between isomorphic sequence representations.
\end{abstract}
\end{comment}


\section{Introduction}

Initial design as well as evolution of successful programming languages often walks a fine line between semantic purity and pragmatic expressiveness. With its declarative roots and creative pragmatic additions Prolog is a long-time survivor in the complex ecosystem of programming languages. We believe that its longevity is due not only to its elegant semantics but also to its creative adaptations to emerging programming language features that respond to evolving software development requirements.

Stream processing, now prevalent in widely used programming languages languages like Java, Python, C\# or JavaScript offers a uniform and (mostly) declarative view on processing finite 
and infinite\footnote{We use ``infinite'' here as a short hand qualifier for data or computation streams of unpredictable, large or very large size.} sequences. Arguably, its advent has been driven, besides the expressiveness lift it provides, by the need of processing big data. This big data problem manifests itself in static incarnations like very large training sets for machine learning, or as dynamic event streams coming from Web search queries and clicks,  or from sensor networks supporting today's fast spreading IOT infrastructure.
 
Several techniques have been used to extend mature programming languages with stream processing. The task has been facilitated by the presence of generalized iterator constructs like Python's generators or by presence of lazy evaluation semantics in functional languages. To extend Prolog with state-of-the-art lazy stream processing capabilities, a few limitations need to be overcome.

The first limitation is that Prolog's resolution mechanism is subject to a fixed depth-first search and a strict evaluation semantics.
While Prolog's depth-first  search mechanism can be complemented with alternative search strategies as shown in \cite{tor} by overriding its disjunction operator, the evaluation mechanism remains ultimately eager. When programming with lists or DCGs, one chains recursive steps
in the body of clauses connected by conjunctions. 

The second limitation, consequence of Prolog's incremental evolution as a programming language, is the presence of procedural state-management and I/O constructs that are
interleaved with its native declarative programming constructs. These range form 
random generator streams to file and socket I/O and dynamic database operations.
While monadic constructs in functional languages \cite{moggi:monads,wadler93:cont}  can provide  a unified view of declarative and procedural state-management operations, logic programming languages still lack a unified approach providing a uniform interface to 
this mix of declarative and procedural language constructs.

A key step in this direction is SWI-Prolog's \cite{swi} 
{\em lazy\_lists} library
\footnote{\url{http://www.swi-prolog.org/pldoc/doc/_SWI_/library/lazy_lists.pl}}
 It uses, ``under the hood'', attributed variables and destructive updates  to provide a declarative view of such state transformers in terms of the list unification steps familiar to the Prolog programmer. 
At the same time, it makes sense to expose stream generators as abstract sequence-manipulation operators, independent of the specific list representation of
possibly infinite, lazily produced streams coming from I/O operations, coroutining logic engines or some complex computations that one might want to declaratively aggregate into an algebra of stream combinators.


This brings us to the main goals of this paper. 
We encapsulate stream processing extensions to Prolog that use
state transformers, lazy lists and first-class logic engines 
%\cite{tarau:parimp99,tarau:cl2000,iclp08:inter,ciclops08:pINTER,bp2011},
\cite{tarau:cl2000,bp2011}, recently added to SWI-Prolog \cite{swi_engines},
into a set of operations organized compositionally in the form of {\em 
stream generators}.
Our generators are similar to Python's {\em yield} mechanism \cite{beazley09} and 
they share features with coroutining constructs now present in a several other widely used programming languages including C\#, Javascript and Lua. At the same time, 
they lift Prolog's expressiveness with lazy evaluation mechanisms similar to non-strict
functional programming languages like Haskell \cite{hudak07} or functional-logic languages like Curry \cite{antoy05}.

We organize our generators as an algebra, wrapped as a library module with a declarative interface, to avoid exposing  operations requiring an implementation with a clear procedural flavor to the Prolog application programmer.

By defining an iso-functor that transports operations between
generators and lazy lists, we offer a choice between 
abstract sequence operations and the concrete list view familiar to Prolog users.

Our implementation of lazy streams is available as a SWI Prolog package at:\\
{\small \url{https://github.com/ptarau/AnswerStreamGenerators/raw/master/lazy_streams-0.5.0.zip } }

The main contributions of this paper are:
\BI
\I a simple and clean approach for setting up lazy streams
\I a lazy list representation of lazy streams to naturally use them as Prolog lists
\I a library of lazy stream sources, transformers and combinators %and sinks
%  (or two libraries if we are counting the lazy\_lists library)
\EI

The paper is organized as follows.

{\Large TODO}

\section{Overview}

{\Large
     Show small examples of the use of lazy streams to give an idea of their expressive power and how neat the code looks\\
     
     USE the stream evaluator with examples here
 }
     
     
%\section{Implementation}

\section{Implementing Stream Generators}
  
\subsection{The Stream Generator Interface}

Generators are built by a family of constructors, encapsulating sequences produced algorithmically or as a result of state transformers interfacing Prolog with the ``outside world'', a design philosophy similar to that of monads in functional languages.

The ``contract'' is that a generator, defined by a closure that moves it one step further is called by the {\tt ask/2} predicate, defined as follows:
\begin{code}
ask(E,_):-is_done(E),!,fail.
ask(E,R):-call(E,X),!,R=X.
ask(E,_):-stop(E),fail.
\end{code}
Note also the checking for terminated generators by {\tt is\_done/1} and the explicit termination by {\tt stop/1} on failure.

The single advancement steps provided by {\tt ask/2} can be morphed into an answer stream generated on backtracking with the infix predicate {\tt in/2}.
\begin{code}
:-op(800,xfx,(in)).

X in Gen:-ask(Gen,A),select_from(Gen,A,X).

select_from(_,X,X).
select_from(Gen,_,X):-X in Gen.
\end{code}

The simplest generator is the infinite constant stream producer {\tt const/2}:
\begin{codex}
const(Constant, Generator)
\end{codex}
that when {\tt ask/2} asks for the next element with
\begin{codex}
call(=(Constant),X)
\end{codex}
it will simply unify {\tt X} and {\tt Constant}.

Another one, relying on externally maintained state is {\tt rand/1}.
\begin{code}
rand(random()).
\end{code}
This generator will, when called by {\tt ask/2}, produce a stream of random floating point numbers between 0 and 1.

A generic constructor for a stream evolving by incremental state changes is
\begin{code}
gen_next(F,State,X):-
  arg(1,State,X),
  call(F,X,Y),
  nb_setarg(1,State,Y).
\end{code}
where {\tt State} acts a container for destructively updated values.


%\subsection{Generators as Simple State Transformers}

In terms of {\tt gen\_next} the stream of natural numbers is defined as:
\begin{code}
nat(nat_next(state(0))).

nat_next(S,X):-gen_next(succ,S,X).
\end{code}

Generators for which state update and value yield are distinct
can be obtained as specializations of {\tt gen\_nextval/3}.
\begin{code}
gen_nextval(Advancer,State,Yield):-
  arg(1,State,X1),
  call(Advancer,X1,X2, Yield),
  nb_setarg(1,State,X2).
\end{code}

For instance, by using {\tt gen\_nextval} one can turn a list into a generator of its elements  in the form of the {\tt list/2} generator constructor.
\begin{code}
list(Xs, gen_nextval(list_step,state(Xs))).

list_step([X|Xs],Xs,X).
\end{code}

\BX
Using some simple generators.
\begin{codex}
?- nat(N),X in N.
N = nat_next(state(1)), X = 0 ;
N = nat_next(state(2)), X = 1 ;
N = nat_next(state(3)), X = 2 .
...

?- list([a,b,c],L),X in L.
L = gen_nextval(list_step, state([b, c])), X = a ;
L = gen_nextval(list_step, state([c])), X = b ;
L = gen_nextval(list_step, state([])), X = c ;
false.
\end{codex}
\EX

We have built similar stream generators in the library package 
{\tt lazy\_streams}, for a range of numbers, turning a finite list into
a an infinite cycle of its elements, as well as stream 
transformers excising a finite slice of a larger, possibly infinite stream,
and taking or dropping an initial segment of a stream.

\subsection{Answer Stream Generators}

When more complex computations are involved, that are cannot be expressed as step-by-step state transformations, a more powerful mechanism is needed. We will use generator constructors based on first class logic engines in this case, but we will expose their workings in terms of the same interface.

\subsubsection{SWI Prolog's engine implementation}

A first-class logic engine \cite{tarau:cl2000,bp2011} can be seen as a Prolog virtual machine that has its own stacks and machine state. 
In their SWI-Prolog implementation. Unlike normal Prolog threads \cite{swi,swi_threads}, they are not associated with an operating system thread. Instead, one asks an engine for a next answer with the predicate {\tt engine\_next/2}. Asking an engine for the next answer attaches the engine to the calling operating system thread and cause it to run until the engine calls {\tt engine\_yield/1} or its associated goal completes with an answer, failure or an exception. After the engine yields or completes, it is detached from the operating system thread and the answer term is made available to the calling thread. Communicating with an engine is similar to communicating with a Prolog system though the terminal: the client decides haow many answers it wants returned and what to do with them.  

Engines are created with the built-in {\tt engine\_create/3} that uses a goal and and answer template as input and returns and engine handle as output. SWI-Prolog engines are created with minimal dynamic stack space and are garbage collected when unreachable.

Implementing the engine API does not assume that a Prolog system supports multi-threading, It only assumes that the virtual machine is fully reentrant, it can be queried and it can stop, yield data and resume execution as a coroutine.

\begin{comment}
As Prolog virtual machines, engines have  an internal state. Thus interacting with them requires a concise and expressive, but ultimately procedural API. This is not very different from what working with attributed variables, instrumental to adding constraint solvers, requires.
\end{comment}

\subsubsection{Answer Stream Generator Constructors}

We design Answer Stream Generators as a wrapper around the SWI-Prolog engine implementation.
We can also keep the goals and answer templates that started the engine to make them reusable. At the same time this external wrapper ensures that engines stay garbage collectable on termination.

The constructor {\tt eng/3} creates a generator as a wrapper around
the {\tt engine\_next(Engine,Answer)} built-in.
\begin{code}
eng(X,Goal,engine_next(Engine)):-engine_create(X,Goal,Engine). 
\end{code}
A variant {\tt ceng/3} is also available if one wants to preserve
the goal and answer template, usable, for instance, to clone
the engine's answer stream, 
operation that makes sense when the Prolog code it is based on 
is free of side effects.

\subsection{The AND-stream / OR-stream Duality}

We call {\em AND-stream / OR-stream duality} the
ability to generate the same answer stream via backtracking (OR-streams) or
as part of a forward moving recursive loop (AND-streams).
As the examples that follow will show,
being oblivious to the choice of generation method they encapsulate,
is a key contributor to the ``expressiveness lift'' answer stream
generators bring to Prolog.

An example of {\em AND-stream} is  implemented
by the generator {\tt and\_nat\_stream}. 
It defines the infinite stream of natural numbers 
by yielding an answer at each step of a recursive loop.
\begin{code}
and_nat_stream(Gen):-eng(_,nat_goal(0),Gen).

nat_goal(N):-SN is N+1,engine_yield(N),nat_goal(SN).
\end{code}

Alternatively, one could define 
an equivalent generator as an OR-stream,  with answers 
produced via  backtracking.
\begin{code}
or_nat_stream(Gen):-eng(N, between(0,infinite,N), Gen).
\end{code}

When using engines, 
both AND-streams and OR-streams can be infinite, as in the
case of the generators {\tt and\_nat\_stream} and {\tt and\_nat\_stream}.
While one can see backtracking over an infinite set of answers as
a ``naturally born'' OR-stream, the ability of the generators to
yield answers from inside an infinite recursive loop is critical
for generating infinite AND-streams.

Note also that generating an answer stream by either of the above methods
is immaterial to the user of the generator which can be seen as a ``black box''.



\section{The Generator Algebra}
We start by describing some of the stream generator operations
that will be organized into a generator algebra 
via an embedded language interpreter.
 
\subsection{Operations on Finite or  Infinite Stream Generators}

\subsubsection{Merging generators: our {\tt sum} operation}

The predicate {\tt sum(+Gen1,+Gen2, -NewGen)} advances by asking each generator, in turn, for one answer. When one terminates, it keeps progressing in the other.
\begin{code}
sum(E1,E2,sum_next(state(E1,E2))).

sum_next(State,X):-State=state(E1,E2),ask(E1,X),!,
  nb_setarg(1,State,E2),
  nb_setarg(2,State,E1).
sum_next(state(_,E2),X):-ask(E2,X).
\end{code}

\subsection{Pairing all elements from two streams: our {\tt product} operation}

The easiest way to implement direct product uses a first-class logic engine.
Designing the recursive loop for possibly infinite stream generators
will need to store finite initial 
segments of the generators as they grow into two lists, initially
empty.
\begin{code}
prod_(E1,E2,E):-eng(_,prod_goal(E1,E2),E).

prod_goal(E1,E2):-ask(E1,A),prod_loop(1,A,E1-[],E2-[]).
\end{code}

The algorithm, expressed by the predicate {\tt prod\_loop}
switches between generators while none of them is done.
After that, it keeps progressing the active generator 
for new pairs, including those selecting an element 
from the stored lists of the terminated generator.
\begin{code}
prod_loop(Ord1,A,E1-Xs,E2-Ys):-
  flip(Ord1,Ord2,A,Y,Pair),
  forall(member(Y,Ys),generate_answer(Pair)),
  ask_generator(E2,B),
  !,
  prod_loop(Ord2,B,E2-Ys,E1-[A|Xs]).
prod_loop(Ord1,_A,E1-_Xs,_E2-Ys):-
  flip(Ord1,_Ord2,X,Y,Pair),
  X in E1,member(Y,Ys),
  generate_answer(Pair),
  fail.
\end{code}

The predicate {\tt flip/5} ensures correct order in a given pair
as  generators take turn being the active one in the recursive loop. 
\begin{code} 
flip(1,2,X,Y,X-Y).
flip(2,1,X,Y,Y-X).
\end{code}

\BX
Working with infinite sums and products. The  predicate {\tt show/1} (defined in the package) shows a short initial segment of a generator.
\begin{codex}
?- nat(N),nat(M),sum(N,M,E),show(E).
[0,0,1,1,2,2,3,3,4,4,5,5]
N = M, M = nat_next(state(6)),
E = sum_next(state(nat_next(state(6)), nat_next(state(6)))).

?- nat(N),nat(M),prod_(N,M,R),show(R).
[0-0,1-0,1-1,0-1,2-1,2-0,2-2,1-2,0-2,3-2,3-1,3-0]
N = M, M = nat_next(state(0)),
R = engine_next(<engine>(4,0x7fa7fe2002c0)).
\end{codex}
\EX

{\Large TODO - sketch the Cantor Unpairing approach}




\subsection{An embedded language interpreter for the algebra}

With our sum and product operations ready, we can proceed designing the embedded language
facilitation more complex forms of generator compositions.

\subsubsection{Working with Sets}

If generators work over sets rather than multisets or arbitrary sequences,
duplicates need to be removed. This can be done either by sorting (which has the advantage
of providing a canonical representation, but assumes finite streams) or by using  a built-in like {\tt distinct/2} which will also work with infinite generators (within the limits of actual memory available).

The predicate {\tt setify} wraps a generator to ensure it produces a set of answers, with duplicates removed.
\begin{code}
setify(E,SE):-new_generator(X,distinct(X,X in E),SE).
\end{code}
In fact, one could just apply the same modification to the goal of a generator and its answer template, but our assumption here is that the generator's engine might be a composition of several engine operations, possibly already in progress.

We can implement our generator algebra as an embedded language via a simple interpreter
(although partial evaluation can make this more efficient). We can also add {\tt !} as a unary prefix operator, used to mark a generator that needs to be cloned.

\begin{code}
%! eval_stream(+GeneratorExpression, -Generator)
% evaluates a generator expressioin to ready to use
% generator that combines their effects
eval_stream(E+F,S):- !,eval_stream(E,EE),eval_stream(F,EF),sum(EE,EF,S).
eval_stream(E*F,P):- !,eval_stream(E,EE),eval_stream(F,EF),prod(EE,EF,P).
eval_stream(E:F,R):- !,range(E,F,R).
eval_stream([X|Xs],L):-!,list([X|Xs],L).
eval_stream({E},SetGen):-!,eval_stream(E,F),setify(F,SetGen).
eval_stream(X^G,E):-!,eng(X,G,E).
eval_stream(A,C):-atomic(A),!,const(A,C).
eval_stream(E,E).
\end{code}
Similarly to the {\tt in/2} predicate, we can make the action of the
interpreter transparent, via the {\tt in\_/2} predicate, also defined as an operator.
\begin{code}
:-op(800,xfx,(in_)).
X in_ E:-eeval(E,EE),X in EE.     
\end{code}


\BX
Applying the embedded language interpreter.
\begin{codex}
?- X in_ ({[a,b,a]}+(1:3)*c).
X = a ;
X = 1-c ;
X = b ;
X = 1-c ;
X = 2-c .
....
\end{codex}
\EX
\subsection{Some algebraic properties of sums and products}

As sum/2 simply interleaves two streams it is clearly associative and 

\BI
\I monoid structure for + and *
\I distributivity
\I commutativity and associativity if the generated sequences represent sets
\EI

\begin{code}
\end{code}

\section{Other Stream Generator Operations}

\subsection{Lazy Functional Programming Constructs}

\subsubsection{Map}

The predicate {\tt map/3} creates a new generator that
applies a predicate with two arguments to the answer stream  of a generator.
It uses {\tt map\_next/3} that advances the generator
and yields the result of applying the closure {\tt F} to what it 
the generator yields.
\begin{code}
map(F,Gen,map_next(F,Gen)).

map_next(F,Gen,Y):-ask(Gen,X),call(F,X,Y).
\end{code}

Our package contains similarly defined {\tt map/N} generators that
apply a predicate with {\tt N-1 arguments} to
{\tt N-1} stream generators.

\subsubsection{Reduce}

\subsection{Wrappers on I/O and stateful procedural Prolog constructs}

One can easily wrap file or socket readers as generators, with the
advantage that details like opening a file, reading and
closing a stream stay hidden, an advantage when, for instance, 
when teaching Prolog to a beginner, as shown by the generator
{\tt term\_reader/2}.

\begin{code}
term_reader(File,next_term(Stream)):-open(File,read,Stream).

next_term(Stream,Term):-
  read(Stream,X),
  ( X\==end_of_file->Term=X
  ; close(Stream),fail
  ).
\end{code}


\section{Generators and Lazy Lists}

While generators provide abstract sequence operations, it is also useful
to emulate as closely as possible the  list operations familiar to the 
Prolog programmer with {\em lazy lists}.

\subsection{Implementing lazy lists using attributed variables}

Lazy lists form a suitable represention of infinite streams of Prolog
terms. Lazy data structures can be implemented in Prolog using
\emph{attributed} variables as a mechanism to extend unification
\cite{10.1007/3-540-55844-6_141}. The lazy function implementation of
Ciao \cite{casas2005functional,lazyCiao}, exploits the widely supported
\texttt{freeze/1} primitive that is usually implemented using attributed
variables. A lazy \emph{list} is represented as a normal Prolog list where the
\emph{tail} is formed by an attributed variable. Normal list traversal
predicates unify this tail with either the empty list (\texttt{[]}) or a
list cell (\texttt{[Head|Tail]}), which triggers the goal associated
with the attributed variable.

A significant disadvantage of this technique is that on backtracking the
lazily computed extension to the list is lost. In addition to causing
overhead for recomputing the value this makes the implementation
unsuitable for fetching data from an external source that cannot
backtrack. A typical example of such a source is a network socket. It is
possible to keep a buffer to support re-fetching content from the socket
but the amount of data we need to buffer depends on the unknown
non-determinism in the Prolog code that processes the list and we cannot
recover if the selected buffer size proves to be too short.

The above limitation can be avoided using \emph{not-backtrackable
assignment} as implemented by various Prolog systems. Where SICStus
solves this problem using a dedicated \emph{mutable term}, SWI-Prolog
provides
\texttt{nb\_setarg/3}\footnote{\url{http://www.swi-prolog.org/pldoc/doc_for?object=nb_setarg/3}}
for assigning an argument in a compound term where the assignment is not
undone on backtracking. SWI-Prolog lazy lists are realized using an
attributed variable that resides in the tail argument of the last list
cell and keeps a reference to this last cell. When triggered, the next
value(s) is/are computed and the tail of the current last cell is set to
the new lazy list using \texttt{nb\_setarg/3}. As this binding is not
undone on backtracking only the first unification triggers the goal
associated with the attributed variable. Initially, a lazy list is
represented using a term \texttt{[dummy|AttVar]}, where the lazy list
itself is the  \texttt{AttVar}.

The above technique is used to implement the library \texttt{pure\_input}, supporting a list view of file or socket operations, 
as well as the generic
\texttt{lazy\_lists}\footnote{\url{http://www.swi-prolog.org/pldoc/doc/_SWI_/library/lazy_lists.pl?show=src#lazy_list/3}}
library. The general goal to create a lazy list is
\texttt{lazy\_list(:Next, +State0, -List)}. This calls
\texttt{call(Next, State0, State1, Head)} to produce the next element.

Lazy lists allow Prolog to handle infinite data streams provided garbage
collection can reclaim the inaccessible head of the list. To make the
head inaccessible, the code cannot keep a reference to the head around
in a variable and although processing the list may be non-deterministic,
this non-determinism must be resolved after examining a finite number of
elements.  The attributed variable trigger and garbage collection ensure
that the window on the stream that is kept in memory is finite and
guaranteed to be large enough to cope with the finite non-determinism.

% ref: https://cliplab.org/papers/lazy-functions-ciclops05.pdf

For instance, 
using the constructor  {\tt lazy\_list/3}, we implement the infinite list of
natural numbers as follows.
\begin{code}
lazy_nats(L):-lazy_list(lazy_nats_next,0,L).

lazy_nats_next(X,SX,X):-succ(X,SX).
\end{code}


%\subsection{The Lazy List View of Prolog Streams}
%\subsection{The  equivalence between Answer stream generators and Lazy Lists}
\subsection{The interoperation between stream gnerators and lazy lists}

The overloading of syntax between the usual lists and lazy lists, 
can be confusing to the
programmer, especially when infinite streams are involved.

\BX
\begin{codex}
?- lazy_nats(Ns),maplist(succ,Ns,Ps).
... loops forever ...
\end{codex}
\EX


The advancing to the next element, happening via a destructive update,
a first class engine's yield operation or an attribute set on the tail of
a lazy list are operationally equivalent.
By lifting this equivalence via Prolog's higher order operations
supported by {\tt call/N} we can easily morph not just  representations 
but also  their operations.
The formal analogy to this is an {\em iso-functor} that in category theory
transports morphisms. 

With help from SWI-Prolog's {\tt lazy\_lists} library, 
generators can be turned into finite or infinite (lazy) lists and vice-versa.
The predicate {\tt gen2lazy(+Generator,-LazyLIst)} turns a possibly infinite
stream generator into a lazy list.
\begin{code} 
gen2lazy(Gen,Ls):-lazy_list(gen2lazy_forward,Gen,Ls).

gen2lazy_forward(E,E,X):-ask(E,X).
\end{code}
As {\tt Gen}  manages its state, so we just pass on the action of the {\tt ask/2}
generator stream advancer.
By observing that the stream constructor {\tt list/2} already works
on lazy lists we define the invers operation {\tt lazy2gen} simply as:
\begin{code}
lazy2gen(Xs, Gen):-list(Xs, Gen).
\end{code}

Next we define the ``iso-functors'' that 
lift this equivalence between data objects to 
one between their operations. We do that as generically as possible,
but one can specialize them to the fixed stream and lazy list domain
for sligtly more efficient code.

The predicate 
{\tt iso\_fun(+Operation, +SourceType, +TargetType, +Arg1, -Result)}
transports a predicate of arity 2 {\tt F(+Arg1, -Arg2)} to a domain where
an operation can be performed and brings back the result.

\begin{code}
iso_fun(F,From,To,A,B):-call(From,A,X),call(F,X,Y),call(To,Y,B).
\end{code}


Similar code is defined for predicates of different arities or
modes, like 
{\tt iso\_fun(+Operation, +SourceType, +TargetType, +Arg1, +Arg2, -Result)} 
or, with different mode
{\tt iso\_fun\_( +Operation, +SourceType, +TargetType, +Arg1, -Res1, -Res2)}.

\begin{codeh}
%
% Transports a predicate of arity 2 F(+A,+B,-C) to a domain where
% an operation can be performed and brings back the result. 
% transports F(+A,+B,-C) 
iso_fun(F,From,To,A,B,C):-
  call(From,A,X),
  call(From,B,Y),
  call(F,X,Y,Z),
  call(To,Z,C).

%! iso_fun_(+Operation,+SourceType,+TargetType,+Arg1, -Res1, -Res2)
%
% Transports a predicate of arity 2 F(+A,-B,-C) to a domain where
% an operation can be performed and brings back the results. 
% transports F(+A,+B,-C) 
iso_fun_(F,From,To,A,B,C):- 
  call(From,A,X),
  call(F,X, Y,Z), % X in, Y,Z out 
  call(To,Y,B),
  call(To,Z,C).
\end{codeh}


This brings us to define {\tt maplist} predicates working also
on infinite list as:

\begin{code}
lazy_maplist(F,LazyXs,LazyYs):-iso_fun(map(F),lazy2gen,gen2lazy,LazyXs,LazyYs).
\end{code}
where {\tt map/3} is the stream generator constructor that applies a binary
predicate to a stream gnerator. In our package, similar definitions for {\tt map/N}
are given for predicates of higher arities, as well as corresponding definitions for
{\tt lazy\_maplist/N} predicates.

\BX
\begin{codex}
?- lazy_nats(Ns),lazy_maplist(succ,Ns,Ps),member(X,Ps).
Ns = [0|_20314],
Ps = [1|_20332],
X = 1,
...
Ns = [0|_20668],
Ps = [1, 2|_20692],
X = 2,
...
Ns = [0|_21022],
Ps = [1, 2, 3|_21052],
X = 3,
...
\end{codex}
\EX


{\Large TODO - sketch the convolution operation, borrowed from lazy lists}




\section{Discussion}


One  can access the N-th element of a  generator in $O(1)$ space.
Lazy lists might or might not need $O(N)$ for the same, depending on possible garbage collection of their unused prefix.
Lazy lists are reusable while new generators must be created if the sequence
needs to be revisited again.
Lazy lists operate via a convenient but {\em concrete} list syntax.
Generators represent {\em abstract} lazy sequences on which one operates directly (via a somewhat procedural API) or declaratively via an algebra encapsulated as an embedded.


\BI
 \I efficiency - avoiding engines when possible reduces memory footprint and avoids term copying
\I no gc is needed when working destructively in constant space - but results can be exposed declaratively
\I algorithms (e.g. convolution of infinite sequences) easier to implement efficiently
\I handling big data streams -can benefit from a library of stream combinators
\EI


Reasons for some of the new things we propose:
\BI
\I what generators can bring in languages like Python \\-e.g. itertools, 
see \url{https://docs.python.org/3/library/itertools.html}
\I lazy evaluation brings to Haskell a declarative handling of infinite sequences

\EI
enhances the expressiveness of  

\BI
\I  applications that one can think of are:
\BI

\I event streams can be seen as generators 

\I scanning multiple tweet streams for a common topic, 
\I finding correlations in multiple stock quote streams 
\I managing IOT signal streams
\I stream processing  can be parallelized when streams originate from things like arrays
\I interfaces to ASP or SAT - returning answers sets as streams can benefit from stream combinator operations
\I combinatorial generation tools - e.g. for for testing purposes - can be encapsulated as lazy streams
\EI
\EI



\section{Related work}

\vskip 1cm
Maybe?
\BI 
\I some history - see
\cite{tarau:parimp99,tarau:cl2000,iclp08:inter,ciclops08:pINTER}
\cite{coord11tarau}
\cite{bp2011}
\I work on delimited continuations \cite{delim}, hookable disjunction \cite{tor}
\I work on pipelines \cite{pipelines}
\EI


{\Large TODO: discuss alternative ways to achieve the same in Prolog e.g. tor \cite{tor}}

{\Large TODO: briefly discuss and compare with Python and mention other generator and coroutine implementations e.g. goroutines, fibers, generator libraries for other languages etc.}

{\Large OPEN QUESTION: can a similar answer generator API be implemented
it terms of  attributed-variables, TOR, delimited continuations? That 
would avoid creating new virtual machines. A different semantics would need to
be faced: would such streams be subject to backtracking. Is that good or bad? 
} a way to do that would be to attach a goal+template as attributes of a variable
and then have the unify hook make the goal call itself with a new argument, while
extracting its "answer" in a lazy\_findall-like mechanism. Thus the simpler question becomes:
{\large can something like lazy\_findall be implemented without engines?}

{\Large related work on streams - e.g. Zaniolo, Gurevich,  Babcock}

\section{Conclusion}

Answer Stream Generators lift the expressiveness of Prolog with language constructs comparable to generators in languages like Python, go, C\verb~#~, Ruby or Lua, and language constructs implicitly available in non-strict functional programming languages like Haskell. 

They offer first-class engine based constructors that can expose sequence 
processing as AND-streams or OR-streams of answers.

The generator algebra together with its the embedded language interpreter supports
the writing compact and elegant code.

{\Large TODO: expand}

\bibliographystyle{acmtrans}
\bibliography{theory,tarau,proglang,biblio,new}

\end{document}
